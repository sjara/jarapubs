# 2022paspeech
Characterization of how neuronal populations in A1 and non-primary AC regions encode FT, VOT, and combinations of FT and VOT

# Producing databases
The file `studyparams.py` contains the list of animals used in this study as well as
relevant file paths and statistical parameters for the database calculations
You need to run the database generation scripts in the order listed here, as each script loads the previous and adds to that.

- `database_cell_locations.py`: Estimates which brain area each cell is from using the processed histology data and the Allen average mouse brain atlas.
- `database_tone_responsive.py`: Estimate responses to pure tones. It creates `SUBJECT_paspeech_tones_pval.h5` (it takes 3 min)
- `database_freq_tuning.py`: Estimate frequency tuning. It creates `SUBJECT_paspeech_freq_tuning.h5` (it takes 1 min)
- `database_am_responsiveness.py`: Estimate responses to AM sounds. It creates `SUBJECT_paspeech_am_pval.h5` (it takes 2 min)
- `database_am_tuning.py`: Estimate tuning to AM rate. It creates `SUBJECT_paspeech_am_tuning.h5` (it takes 42s)
- `database_speech_responsive.py`: Estimates responsiveness to speech sounds (FT and VOT). It creates `SUBJECT_paspeech_speech_pval.h5` (it takes 3.5 min)
- `database_combine_subjects`: Combines the databases from each individual subject into one database. It creates `fulldb_speech_tuning.h5`

 For all databases, "BEST" indicates the maximum absolute value difference between the mean firing rate for a given stimulus (e.g. modulation rate) and baseline firing rate for each cell.
- `database_generation_funcs.py`: Contains functions called during database generation.

# Database contents

- The initial database is generated by `celldatabase.generate_cell_database_from_subjects()`, as part of the `database_cell_locations.py` script.
    - It contains columns according to the inforec files (``subject``, ``date``, etc)
    - And the spike sorting results (``cluster``, ``spikeShape``, etc).
    - It also creates columns `x_coord`, `y_coord`, `z_coord`, and `recordingSiteName`, which are the coordinates in allen CCF space and the brain area label for that location in the CCF.
- `SUBJECT_paspeech_tones_pval.h5` adds columns for:
    - `amMinPvalOnset`, which is the minimum pValue (wilcoxon) from the comparison between the evoked firing rate from the onset (first 100ms) of each AM stimulus and the baseline firing rate.
    - `amIndexMinPvalOnset`, which is the index of which AM stimulus has the minimum pvalue, 'amFiringRateBaseline', is the average baseline firing rate (200ms before stimulus onset) for each cell.
    - `amFiringRateBestOnset` is the firing rate from the stimulus that had the maximum (absolute value) difference between the mean firing rate for a given modulation rate and baseline firing rate for each cell.
    - `amIndexBestOnset` is the index of which am stimulus was the best.
    - `amFiringRateMaxOnset` and `amFiringRateMinOnset` are the max/min of the evoked firing rate averaged by AM stimulus.
    - All of these measures are repeated for the `Sustain` period of the stimulus presentation (100-500ms of the AM stimulus).
- `SUBJECT_paspeech_am_tuning.h5` adds columns for:
    - `amSelectivityPvalOnset` and `amSelectivityPvalSustain`, which are the pvalues from the kruskal-wallis h test comparing the spike counts for each AM rate during the Onset (0-100ms) and Sustain (100-500ms) periods of the AM stimulus.
    - `amMaxSyncRate` which is the highest AM rate the cell phase-locks to.
- `SUBJECT_paspeech_tones_pval.h5` adds columns for:
    - `toneMinPval` and `toneIndexMinPval` which are the minimum pvalue (wilcoxon) and index of the stimulus that had the minPval for the comparison between the evoked firing rate (for each stimulus) and baseline firing rate (200ms before stimulus onset).
    - `toneFiringRateBaseline` which is the average baseline firing rate for each cell.
    -  `toneFiringRateBest` and `toneIndexBest` which is the firing rate (and index of which tone was "best") to the stimulus that evoked the maximum difference (absolute value) between evoked firing rate and the baseline firing rate.
- `SUBJECT_paspeech_freq_tuning.h5`: adds columns for:
    - `toneSelectivityPval`, which is the pvalue for the Kruskal-wallis test comparing the firing rates during the stimulus presentation for each pure tone presented.
    - `toneFiringRateBest` and `toneIndexBest`, which are the firing rate and index as to which stimulus evoked the maximum difference (absolute value) between the evoked firing rate and the baseline firing rate. there is a "best" for both onset and Sustain periods (0 - 50ms and 50-100ms, respectively).
    - `toneIntensityThreshold` and `toneCharactFreq` which are the lowest intensity presented that elicited a response from the cell and the charateristic frequency for each cell.
    - And parameters for the gaussian fit to the tuning data: `toneGaussianRsquare`, `toneGaussianA`, `toneGaussianX0`, `toneGaussianSigma` and `toneGaussianY0`.
- `SUBJECT_paspeech_speech_pval.h5`: adds columns for:
    - `speechMinPvalOnset`, `ftIndexBestOnset`, `votIndexBestOnset`, which is the minimum pvalue (wilcoxon) and the ft and vot indices (respectively) for the comparison between the evoked firing rate during the onset (0-120ms) and the baseline firing rate (200ms before stimulus onset).
    - `speechFiringRateBaseline` is the baseline firing rate for each cell.
    - `speechFiringRateBestOnset`, `ftIndexBestOnset`, `votIndexBestOnset` which is the average firing rate and the ft/vot indices of the stimulus that evoked the maximum difference (absolute value) between the stimulus evoked and baseline firing rates.
    - `speechFiringRateMaxOnset` amd `speechFiringRateMinOnset` are the max/min of the evoked firing rate averaged by speech stimulus.
    - All of these measures are repeated for the `Sustain` period of the stimulus presentation (120-240ms).

## Base stats:
These are additional columns calculated for all cells:

## Indices:
These are additional columns calculated for a selected set of cells:

- *VOT selectivity index*: A-B/A+B, where A is the average firing rate during the stimulus for the VOT stimulus that evokes the highest FR of the 4 VOT levels (and FT is constant at either max or min), and B is the average firing rate during the stimulus for the VOT stimulus that evokes the lowest FR of the 4 VOT levels (and FT is constant at either max or min)
- *FT selectivity index*: Same as above, but for FT


# Generate files
`generate_psycurve_cohortAverages.py` : This generates a population average psychometric stored in `data_cohort_average_psycurves.npz`
`generate_psycurve_exampleMouse.py` :  This generates a psychometric for a single example mouse, stored in `data_example_mice_psycurves.npz`
`generate_selectivity_indices.py`: This generates FT and VOT selectivity indices for each cell, stored in `data_selectivity_indices.npz`
`generate_shuffle_speech_trials.py`: This generates shuffled FT and VOT selectivity index distributions for each cell, also saves shuffled min/max firing rate for each cell, stored in `data_shuffledSIs.npz`

# Figures
All figures require access to the databases, the clustered ephys data, and the behavior data.

## Figure 1 (Mice can discriminate speech sounds)
Created by `figure_behavior.py`.
- Panel A: 3 spectrograms: /ba/, /pa/, and /da/ at 8x human freq range (using sounds from `jarahub:/data/jarasounds/ft_vot_8x_20220115/`)
- Panel B: 2AFC cartoon
- Panel C: Psycurve for example mouse performing VOT task (using data generated from `generate_psycurve_exampleMouse.py`)
- Panel D: Population averaged Psycurve from the VOT cohort (using data generated from `generate_psycurve_cohortAverages.py`)
- Panel E: Psycurve for example mouse performing FT task (using data generated from `generate_psycurve_exampleMouse.py`)
- Panel F: Population averaged Psycurve from the FT cohort (using data generated from `generate_psycurve_cohortAverages.py`)

## Figure 2 (Ephys methods and cell responsiveness)
Created by `figure_neuropix_ac.py`
- Panel A: Cartoon of headfixed, awake mouse ephys
- Panel B: Diagram of sound matrix
- Panel C: Histology image of recording track
- Panel D: Scatter plot of recording location of each cell. (Using data generated from `generate_selectivity_indices.py`) Add AC areas image in inkscape.
- Panel E: Donut plots of fraction of cells in AudP, AudD, AudV and TeA that were responsive to our speech sounds, responsive to AM/PT but not speech sounds, or not sound responsive (using data generated from `generate_selectivity_indices.py`)

## Figure 3 (Example cells)

## Figure 4 (VOT/FT Selectivity summary figure)
Created by `figure_selectivityVsLocation.py`
- Panel A: Plot of VOT selectivity indices (color map) in A-P/D-V space (using data generated from `generate_selectivity_indices.py`). Add AC areas image in inkscape.
- Panel B: Donut plots of fraction of VOT selective cells (among speech responsive cells) for each Aud Area (using data generated from `generate_selectivity_indices.py`).
- Panel C: VOT selectivity indices binned in D-V space (using data generated from `generate_selectivity_indices.py` and `generate_shuffle_speech_trials.py`)
- Panel D: VOT selectivity indices binned in A-P space (using data generated from `generate_selectivity_indices.py` and `generate_shuffle_speech_trials.py`)
- Panels E-H: As in Panels A-D, but for FT rather than VOT

## Figure 5 (Mixed selectivity summary figure)
